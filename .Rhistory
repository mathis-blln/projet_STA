setwd("~/Ensai/3A/Series_temp/Project/projet_STA")
# Load libraries
library(rugarch)
library(dplyr)
library(tseries)
# Load data
data <- read.csv("data/output/final_database.csv")
data$Date <- as.Date(data$Date, format = "%Y-%m-%d")
########## GARCH MODEL
# Volatility clusters in time series data
plot.ts(data$Return)
# Autocorrelation of the return
acf(data$Return)
# Autocorrelation of the squared return
acf(data$Return**2)
# Load libraries
library(rugarch)
library(dplyr)
library(tseries)
# Load data
data <- read.csv("data/output/final_database.csv")
data$Date <- as.Date(data$Date, format = "%Y-%m-%d")
########## GARCH MODEL
# Volatility clusters in time series data
plot.ts(data$Return)
## Estimation of order of GARCH model
acf(data$Return**2 - mean(data$Return**2))
data_train <- data[data$Date < "2023-01-01",]
data_test <- data[data$Date >= "2023-01-01",]
# Use of ARMA representation of e^2
find_garch <- function(p_min,p_max,q_min,q_max, data, dist="norm"){
best_aic <- Inf
best_order <- c(0, 0, 0)
results <- data.frame(p = integer(),
q = integer(),
aic = numeric(),
relative_gap = numeric(),
stringsAsFactors = FALSE)
for (p in p_min:p_max) {
for (q in q_min:q_max) {
garch_spec <- ugarchspec( variance.model = list(model ="sGARCH", garchOrder = c(p, q)),
mean.model = list(armaOrder = c(0, 0)),
distribution.model =dist)
out <-  ugarchfit(spec =garch_spec, data = data)
current_aic <- infocriteria(out)[1]*length(data)
if (current_aic < best_aic) {
best_aic <- current_aic
best_order <- c(p, 0, q)
}
results <- rbind(results, data.frame(p = p,
q = q,
aic = current_aic,
relative_gap = NA))
#}
}
}
results$relative_gap <- (results$aic - best_aic)*100 / best_aic
return(results)
}
# Find the best GARCH model
p_min <- 0
p_max <- 1
q_min <- 1
q_max <- 2
results<- find_garch(p_min, p_max, q_min, q_max, data_train$Return**2,dist="norm")
# latex table
print(xtable::xtable(results, type = "latex"))
# Fonction pour ajuster un modèle GARCH avec une distribution spécifiée
fit_garch <- function(data, n_test, distribution = "norm", model ="sGARCH",submodel=NULL, garch_order = c(1, 1), arma_order = c(0, 0)) {
# Spécification du modèle GARCH
garch_spec <- ugarchspec(
variance.model = list(model = model, garchOrder = garch_order, submodel=submodel),
mean.model = list(armaOrder = arma_order),
distribution.model = distribution
)
# Ajustement du modèle GARCH
garch_fit <- ugarchfit(spec = garch_spec, data = data, out.sample = n_test)
# Fitted values
fitted <- list()
fitted$sigma <-garch_fit@fit$sigma
fitted$mean <- garch_fit@fit$fitted
return(list(garch_fit = garch_fit, fitted = fitted))
}
# Fonction pour générer des prévisions avec un modèle GARCH ajusté
forecast_garch <- function(garch_fit, data, n_test, n_ahead = 1) {
garch_forecast <- ugarchforecast(garch_fit, data = data, n.ahead = n_ahead, n.roll = n_test - 1)
forecast <- list()
forecast$sigma <- as.numeric(garch_forecast@forecast$sigmaFor)
forecast$mean <- as.numeric(garch_forecast@forecast$seriesFor)
return(forecast)
}
# Compute performance
performance <- function(predicted, realized){
N <- length(realized)
# Root Mean Squared Error (RMSE)
rmse <- sum((predicted - realized)**2) / N
# Mean Absolute Error (MAE)
mae <- (1 / N) * sum(abs(predicted - realized))
# Heteroscedasticity-adjusted MAE (HMAE)
hmae <- (1 / N) * sum(abs( 1 - predicted / realized))
return(list(rmse = rmse, mae = mae, hmae = hmae))
}
# Fonction pour effectuer le workflow complet
run_garch <- function(data,n_test, distribution = "norm",model ="sGARCH",submodel= NULL, garch_order = c(1, 1), arma_order = c(0, 0)) {
N <- length(data)
data_train <- data[1:(N - n_test)]
data_test <- data[(N- n_test + 1):N]
# Ajustement du modèle
fit_results <- fit_garch(data,n_test,distribution,model, submodel, garch_order, arma_order)
garch_fit <- fit_results$garch_fit
# Prévisions
forecast <- forecast_garch(garch_fit, data,n_test, n_ahead = 1)
# Proxy de volatilité
# # Lorsqu’on ne dispose pas de données intrajournalières pour calculer des proxies comme la Realized Volatility
# # ou la Realized High-Low Volatility, le deuxième meilleur proxy de la variance est généralement le carré du rendement.
vol_proxy_test <- sqrt(data_test^2)
vol_proxy_train <- sqrt(data_train^2)
# Performance
perf_train <- performance(sigma(garch_fit), vol_proxy_train)
perf_test <- performance(forecast$sigma, vol_proxy_test)
return(list(fit = garch_fit, fitted = fit_results$fitted, forecast = forecast, performance_train = perf_train, performance_test = perf_test, vol_proxy_test = vol_proxy_test, vol_proxy_train=vol_proxy_train))
}
n_test <- nrow(data_test)
res_norm<- run_garch(data$Return, n_test, distribution = "norm",model ="sGARCH", submodel=NULL, garch_order = c(1, 1), arma_order = c(0, 0))
res_norm$fit
# Jacques bera test for normality
jarque.bera.test(res_norm$fit@fit$residuals)
# Example: list of performance metrics
performance_results <- list(
res_norm$performance_test,
res_std$performance_test,
res_sstd$performance_test,
res_ged$performance_test,
res_sged$performance_test
)
# Convert list to a dataframe
performance_df <- bind_rows(performance_results, .id = "Model") %>%
mutate(Model = c("Norm", "Std", "Sstd", "Ged", "Sged"))
# View the structured dataframe
print(performance_df)
# Example: list of performance metrics
performance_results <- list(
res_norm$performance_test,
res_std$performance_test,
res_sstd$performance_test,
res_ged$performance_test,
res_sged$performance_test
)
n_test <- nrow(data_test)
res_norm<- run_garch(data$Return, n_test, distribution = "norm",model ="sGARCH", submodel=NULL, garch_order = c(1, 1), arma_order = c(0, 0))
res_norm$fit
#### Regarder le paramètre de forme pour indication sur les lois à tester
# Jacques bera test for normality
jarque.bera.test(res_norm$fit@fit$residuals)
# Print performance
#res_norm$performance_train
res_norm$performance_test
info <- infocriteria(res_norm$fit)
# Extract AIC and BIC
info[1]
info[2]
########## GARCH(1,1) model with Student distribution
res_std<- run_garch(data$Return, n_test, distribution = "std",model ="sGARCH", submodel=NULL, garch_order = c(1, 1), arma_order = c(0, 0))
# Print performance
res_std$performance_test
########## GARCH(1,1) model with skew student distribution
res_sstd<- run_garch(data$Return, n_test, distribution = "sstd", model ="sGARCH", submodel=NULL, garch_order = c(1, 1), arma_order = c(0, 0))
# Print performance
res_sstd$performance_test
########## GARCH(1,1) model with generalized error distribution
res_ged<- run_garch(data$Return, n_test, distribution = "ged",model ="sGARCH", submodel=NULL, garch_order = c(1, 1), arma_order = c(0, 0))
# Print performance
res_ged$performance_test
########## GARCH(1,1) model with skewed generalized error distribution
res_sged<- run_garch(data$Return, n_test, distribution = "sged",model ="sGARCH", submodel=NULL, garch_order = c(1, 1), arma_order = c(0, 0))
# Print performance
res_sged$performance_test
# Example: list of performance metrics
performance_results <- list(
res_norm$performance_test,
res_std$performance_test,
res_sstd$performance_test,
res_ged$performance_test,
res_sged$performance_test
)
# Convert list to a dataframe
performance_df <- bind_rows(performance_results, .id = "Model") %>%
mutate(Model = c("Norm", "Std", "Sstd", "Ged", "Sged"))
# View the structured dataframe
print(performance_df)
#### Plot results of best model
res_sstd$forecast$date <- data_test$Date
res_sstd$fitted$date <- data_train$Date
plot(data_train$Date, data_train$Return, type = "l", col = "black", xlab = "Date", ylab = "Return")
lines(res_sstd$fitted$date, res_sstd$fitted$sigma, col = "red")
lines(data_test$Date, data_test$Return, type = "l", col = "blue", xlab = "Date", ylab = "Return", main = "GARCH(1,1) Forecast")
lines(res_sstd$forecast$date, res_sstd$forecast$sigma, type = "l", col = "red", xlab = "Date", ylab = "Volatility", main = "GARCH(1,1) Forecast")
legend("bottomleft", legend = c("Train","Test", "Volatility predicted"), col = c("black","blue", "red"), lty = 1:1, cex = 0.8)
########## eGARCH(1,1) model with skew student distribution
res_sstd_egarch<- run_garch(data$Return, n_test, distribution = "sstd" ,model ="eGARCH", submodel=NULL, garch_order = c(1, 1), arma_order = c(0, 0))
# Print performance
res_sstd_egarch$performance_test
########## TGARCH(1,1) model with skew student distribution
res_sstd_tgarch<- run_garch(data$Return, n_test, distribution = "sstd" ,model ="fGARCH",submodel="TGARCH", garch_order = c(1, 1), arma_order = c(0, 0))
# Print performance
res_sstd_tgarch$performance_test
## add to performance df
performance_results <- list(
res_norm$performance_test,
res_std$performance_test,
res_sstd$performance_test,
res_ged$performance_test,
res_sged$performance_test,
res_sstd_egarch$performance_test,
res_sstd_tgarch$performance_test
)
# Convert list to a dataframe
performance_df <- bind_rows(performance_results, .id = "Model") %>%
mutate(Model = c("Norm", "Std", "Sstd", "Ged", "Sged", "Sstd_egarch", "Sstd_tgarch"))
performance_df
#load packages
library(quantmod)
library(rvest)
library(reshape2)
library(plotly)
library(akima)
#get underlying stock info and last trade date
symbol <- "AAPL"
priceInfo <- getQuote(symbol)
divYield <- getQuote(symbol, what = yahooQF("Dividend Yield"))$`Dividend Yield`
#load packages
library(quantmod)
library(rvest)
library(reshape2)
library(plotly)
library(akima)
#get underlying stock info and last trade date
symbol <- "AAPL"
priceInfo <- getQuote(symbol)
lastPrice <- priceInfo$Last
divYield <- getQuote(symbol, what = yahooQF("Dividend Yield"))$`Dividend Yield`
if(is.na(divYield)){divYield <- 0}
date <- as.Date(priceInfo$`Trade Time`)
#settings for moneyness and time to maturity
moneynessBoundaries <- c(0.85,1.15)
ttmBoundaries <- c(7, 180)
#scrape full site
baseUrl <- paste0("https://finance.yahoo.com/quote/",symbol,"/options")
baseHTML <- read_html(baseUrl)
expiriesUNIX <- expiriesUNIX[sel]
expiries <- expiries[sel]
timeToMats <- timeToMats[sel]
#loop over expiries to get calls and puts
calls <- NULL
puts <- NULL
for(i in 1:length(expiriesUNIX)){
expiryUrl <- paste0(baseUrl,"?date=",expiriesUNIX[i])
expiryHTML <- read_html(expiryUrl)
tmpCalls <- expiryHTML %>% html_nodes(".calls") %>% html_table()
if(length(tmpCalls) > 0){
tmpCalls <- tmpCalls[[1]]
#sometimes column names are in uppercase, sometimes not
colnames(tmpCalls) <- tolower(colnames(tmpCalls))
#remove thousand separator and convert to numeric if applicable
tmpCalls$strike <- as.numeric(gsub(",","",tmpCalls$strike))
#add time to maturity
tmpCalls$ttm <- timeToMats[i]
#calculate moneyness
tmpCalls$moneyness <- lastPrice/tmpCalls$strike
#convert yahoo finance IV to numeric
tmpCalls$ivOrig <- as.numeric(gsub("%","",gsub(",","",tmpCalls$`implied volatility`)))/100
calls <- rbind(calls, tmpCalls)
}
tmpPuts <- expiryHTML %>% html_nodes(".puts") %>% html_table()
if(length(tmpPuts) > 0){
tmpPuts <- tmpPuts[[1]]
#sometimes column names are in uppercase, sometimes not
colnames(tmpPuts) <- tolower(colnames(tmpPuts))
#remove thousand separator and convert to numeric if applicable
tmpPuts$strike <- as.numeric(gsub(",","",tmpPuts$strike))
#add time to maturity
tmpPuts$ttm <- timeToMats[i]
#calculate moneyness
tmpPuts$moneyness <- tmpPuts$strike/lastPrice
#convert yahoo finance IV to numeric
tmpPuts$ivOrig <- as.numeric(gsub("%","",gsub(",","",tmpPuts$`implied volatility`)))/100
puts <- rbind(puts, tmpPuts)
}
}
#select only calls that have traded during the last 5 minutes of the stocks last trading day
calls <- calls[strptime(calls$`last trade date`,format = "%Y-%m-%d %I:%M%p") >= strptime(paste0(date," 3:55PM EDT"), format = "%Y-%m-%d %I:%M%p"),]
#select only puts within the applicable moneyness boundaries
puts <- puts[puts$moneyness >= moneynessBoundaries[1] & puts$moneyness <= moneynessBoundaries[2],]
#select only puts that have traded during the last 5 minutes of the stocks last trading day
puts <- puts[strptime(puts$`last trade date`,format = "%Y-%m-%d %I:%M%p") >= strptime(paste0(date," 3:55PM EDT"), format = "%Y-%m-%d %I:%M%p"),]
#generalized black scholes merton model
gBSM <- function(S, X, sigma, r, q, ttm, type){
#S = stock price
#X = strike price
#sigma = volatility
#r = risk free interest rate
#q = dividend yield
#ttm = time to maturity in days
#type = option type
b <- r - q
t <- ttm/365.25
d1 <- (log(S / X) + (b + sigma^2 / 2) * t) / (sigma * sqrt(t))
d2 <- d1 - sigma * sqrt(t)
if(type == "call"){
price <- S * exp((b - r) * t) * pnorm(d1) - X * exp(-r * t) * pnorm(d2)
}else if (type == "put"){
price <-  (X * exp(-r * t) * pnorm(-d2) - S * exp((b - r) * t) * pnorm(-d1))
}
return(price)
}
#objective function
volOptimFun <- function(sigma, price, S, K, r, q, ttm, type){
abs(price - gBSM(S, K, sigma, r, q, ttm, type))
}
#wrapper for the optimization function so it can be used with apply
getIV <- function(x, S, r, q, type){
res <- optimize(volOptimFun, interval = c(0, 2), price = as.numeric(x["ask"]), S = S, K = as.numeric(x["strike"]), r = r, q = q, ttm = as.numeric(x["ttm"]), type = type)
return(res$minimum)
}
#calculating IV
calls$iv <- apply(calls, 1, getIV, S = lastPrice, r = 0.0011, q = divYield, type = "call")
puts$iv <- apply(puts, 1, getIV, S = lastPrice, r = 0.0011, q = divYield, type = "put")
#create grids
ivGridCalls <- acast(calls, ttm ~ moneyness, value.var = "iv")
ivGridPuts <- acast(puts, ttm ~ moneyness, value.var = "iv")
#get coordinates of NAs in grid
toInterpolate <- which(is.na(ivGridCalls))
coords <- cbind(toInterpolate%%dim(ivGridCalls)[1], toInterpolate%/%dim(ivGridCalls)[1] + 1)
coords[coords[,1] == 0, 2] <- coords[coords[,1] == 0, 2] - 1
coords[coords[,1] == 0, 1] <- dim(ivGridCalls)[1]
#loop through NAs and interpolate
for(i in 1:nrow(coords)){
#get the coordinates of a 10x10 area around the missing value
x1 <- max(coords[i,1] - 10, 1)
x2 <- min(coords[i,1] + 10, dim(ivGridCalls)[1])
y1 <- max(coords[i,2] - 10, 1)
y2 <- min(coords[i,2] + 10, dim(ivGridCalls)[2])
#get the moneyness/time to mat combination of the missing value
x0 <- as.numeric(rownames(ivGridCalls)[coords[i,1]])
y0 <- as.numeric(colnames(ivGridCalls)[coords[i,2]])
#get the part of the grid that is used to interpolate and remove all missing values that are present
interpGrid <- ivGridCalls[x1:x2,y1:y2]
interpGrid <- melt(interpGrid)
interpGrid <- na.omit(interpGrid)
#interpolate linearly
interpVal <- interp(x = interpGrid$Var1, y = interpGrid$Var2, z = interpGrid$value,
xo = x0, yo = y0,
linear = TRUE, extrap = TRUE)$z[1,1]
#if linear interpolation doesnt yield a result, use spline interpolation
if(is.na(interpVal)){
interpVal <- interp(x = interpGrid$Var1, y = interpGrid$Var2, z = interpGrid$value,
xo = x0, yo = y0,
linear = FALSE, extrap = TRUE)$z[1,1]
}
#if the resulting value is clearly wrong, e.g. negative or way outside the values that are used to interpolate,
#leave it as NA
if(interpVal < 0 | interpVal > max(interpGrid$value * 1.5)){
interpVal <- NA
}
#replace the value with the result of the interpolation
ivGridCalls[coords[i,1],coords[i,2]] <- interpVal
}
#plot the resulting implied volatility surface
xaxx <- list(
gridcolor='rgb(255, 255, 255)',
zerolinecolor='rgb(255, 255, 255)',
showbackground=TRUE,
backgroundcolor='rgb(230, 230,230)',
title = "Moneyness"
)
yaxx <- list(
gridcolor='rgb(255, 255, 255)',
zerolinecolor='rgb(255, 255, 255)',
showbackground=TRUE,
backgroundcolor='rgb(230, 230,230)',
title = "Time To Maturity"
)
zaxx <- list(
gridcolor='rgb(255, 255, 255)',
zerolinecolor='rgb(255, 255, 255)',
showbackground=TRUE,
backgroundcolor='rgb(230, 230,230)',
tickformat = "%",
title = "Implied Volatility"
)
fig <- plot_ly(x = colnames(ivGridCalls), y =  rownames(ivGridCalls), z = ivGridCalls)
fig <- fig %>% add_surface()
fig <- fig %>% layout(scene = list(xaxis=xaxx, yaxis=yaxx, zaxis = zaxx))
fig <- fig %>% plotly::colorbar(title = "", x = 0.9, y = 0.75, tickformat = "%")
fig
