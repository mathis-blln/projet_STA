---
title: "projet_STA"
author: "BOUILLON Mathis"
date: "2024-12-12"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Projet de Séries Temporelles Avancées 


### Modèle ARDL : une définition formelle

Le modèle ARDL (AutoRegressive Distributed Lag) est une spécification économétrique qui permet de modéliser la relation dynamique entre une variable dépendante \( y_t \) et un ensemble de variables explicatives \( x_{it} \). 

La forme générale d’un modèle ARDL(p, q) peut s’écrire comme suit :

\[
y_t = \alpha + \sum_{i=1}^p \phi_i y_{t-i} + \sum_{j=0}^q \sum_{i=1}^k \beta_{ij} x_{i,t-j} + \varepsilon_t
\]

où :

- \( y_t \) est la variable dépendante à l’instant \( t \),
- \( x_{i,t-j} \) sont les variables explicatives (avec \( i = 1, ..., k \) et \( j = 0, ..., q \) pour capturer les décalages),
- \( \alpha \) est la constante,
- \( \phi_i \) sont les coefficients des termes autorégressifs,
- \( \beta_{ij} \) sont les coefficients des termes à retards distribués,
- \( \varepsilon_t \) est le terme d’erreur.

Ce modèle est utilisé pour analyser les relations à court terme et à long terme entre les variables. En cas de cointégration entre \( y_t \) et \( x_{it} \), une transformation du modèle ARDL en un modèle de correction d’erreur (ECM) permet de quantifier les ajustements vers l’équilibre de long terme.

p est l'ordre de l'AR, et q est le nombre de retards appliqué aux variables explicatives ou exogènes au modèle. 



```{r, include = FALSE}

# Définir un miroir CRAN (important pour éviter les erreurs)
options(repos = c(CRAN = "https://cran.rstudio.com/"))

# Installer TinyTeX si nécessaire
if (!require("tinytex")) install.packages("tinytex")
if (!tinytex::is_tinytex()) tinytex::install_tinytex() 

if (!require("quantmod")) install.packages("quantmod")
if (!require("tidyverse")) install.packages("tidyverse")
if (!require("fBasics")) install.packages("fBasics")
if (!require("tseries")) install.packages("tseries")
if (!require("urca")) install.packages("urca")

library(quantmod)
library(tidyverse)
library(fBasics)
library(tseries)
library(urca)

```

# Récupération des données du CAC 40 et visualisation : 

```{r}
# Télécharger les données du CAC 40
cac40 <- getSymbols("^FCHI", src = "yahoo", from = "1990-01-01", to = "2024-10-31", auto.assign = FALSE)

# Extraire uniquement les prix de clôture
cac40_close <- na.omit(Cl(cac40))  # 'Cl()' extrait la colonne de clôture
#nous pouvons également considérer d'autres indicateurs tq le max sur la journée, le min...
colnames(cac40_close) <- "Close"

#Visualisation de la série 

autoplot(cac40_close) +
  ggtitle("Indice CAC 40 pour la période 1990-2023") +
  xlab("Date") +
  ylab("Clôture") +
  theme_minimal() + 
  theme(plot.title = element_text(hjust = 0.5)) 
```


Nous pouvons déjà voir que la série présente une tendance linéaire claire. Il n'y a pas forcément de saisonnalité (plutôt des grosses chutes lors des crises globales)

# Analyse préliminaire de la série de l'indice 

## Valeurs manquantes 

```{r}
# Vérifier s'il y a des valeurs manquantes dans la série
missing_values <- sum(is.na(cac40_close))

# Afficher le nombre de valeurs manquantes
print(paste("Nombre de valeurs manquantes :", missing_values))

# Si des valeurs manquantes existent, afficher leurs dates
if (missing_values > 0) {
  missing_dates <- index(cac40_close)[is.na(cac40_close)]
  print("Dates avec valeurs manquantes :")
  print(missing_dates)
} else {
  print("Aucune valeur manquante dans la série.")
}

```

## Observation de la tendance (linéaire)

```{r}
# Add a linear trend
autoplot(cac40_close) +
  geom_smooth(method = "lm", se = FALSE, color = "red") +
  ggtitle("Linear Trend of the CAC 40 Index") +
  xlab("Date") +
  ylab("Closing Price") +
  theme_minimal()

```

```{r}
#avec le R**2

# Créer une variable temporelle
time <- as.numeric(index(cac40_close))

# Ajuster un modèle linéaire : Prix ~ Temps
lm_model <- lm(coredata(cac40_close) ~ time)

# Résumé du modèle
summary(lm_model)

```


Nous allons maintenant regarder les log returns de cette série (ce qui est équivalent à une première différenciation de la série) afin de voir si elle est stationnaire ou non 

```{r}
# Calcul des rendements logarithmiques
log_returns <- diff(log(cac40_close))

# Visualisation des rendements
autoplot(log_returns) +
  ggtitle("Rendements logarithmiques du CAC 40") +
  xlab("Date") +
  ylab("Log-returns") +
  theme_minimal()

# Statistiques descriptives des rendements
basicStats(log_returns)

# Histogramme des rendements
ggplot(data = data.frame(log_returns = coredata(log_returns)), aes(x = log_returns)) +
  geom_histogram(bins = 50, fill = "lightblue", color = "black") +
  ggtitle("Distribution des rendements logarithmiques") +
  xlab("Log-returns") +
  ylab("Fréquence") +
  theme_minimal()

```

On checke la stationnarité de la série avec un test de Dickey : 

```{r}
# Test ADF sur les rendements logarithmiques
adf_test <- adf.test(na.omit(log_returns))

# Afficher les résultats du test
print(adf_test)

```
La série des rendements est bien stationnaire. 
Nous pouvons également le tester avec le test KPSS : 

```{r}
# Test KPSS sur les rendements logarithmiques
kpss_test <- ur.kpss(na.omit(log_returns))

# Résumé des résultats
summary(kpss_test)

```

Le test-statistic obtenu (0.0543) est bien inférieur à toutes les valeurs critiques obtenues à pour chaque seuil. Cela signifie que nous ne rejetons pas l'hypothèse nulle i.e. que les rendements logarithmiques du CAC 40 sont stationnaires autour d'une moyenne constante.


#Construction de la base de données 

```{r}
library(readr)
library(ggplot2)  # Pour créer les graphiques
library(zoo)  # Pour gérer les périodes trimestrielles

```

```{r}
# pour les données de la france 
library(dplyr)  # Pour manipuler les données
library(tidyr)


eco_data <- read_csv("OECD.ECO.MAD,DSD_EO@DF_EO,1.2+FRA.UNR+CPIH_YTYPCT+IRL+IRS+YPH+GDP+GDPV+IRCB.Q.csv",
                     show_col_types = FALSE)
colnames(eco_data)
eco_data$TIME_PERIOD <- as.yearqtr(eco_data$TIME_PERIOD, format="%Y-Q%q")


eco_data_wide <- eco_data %>%
  dplyr::select(TIME_PERIOD, MEASURE, OBS_VALUE) %>%
  tidyr::pivot_wider(
    names_from = MEASURE,   # Les variables (comme GDP, GNP) deviendront des colonnes
    values_from = OBS_VALUE # Les valeurs associées aux variables
  ) %>%
  arrange(TIME_PERIOD)



# Liste des variables (exclure TIME_PERIOD)
variables <- colnames(eco_data_wide)[-1]

# Créer un graphique pour chaque variable, un par un
for (var in variables) {
  print(
    ggplot(eco_data_wide, aes_string(x = "TIME_PERIOD", y = var)) +
      geom_point(color = "blue") +
      labs(title = paste("Nuage de points pour", var),
           x = "Temps (Trimestres)",
           y = var) +
      theme_minimal()
  )
}
``` 

```{r}
#pour les US

eco_data_us <- read_csv("OECD.ECO.MAD,DSD_EO@DF_EO,1.2+USA.CPI+UNR+IRCB.Q.csv",
                     show_col_types = FALSE)
eco_data_us$TIME_PERIOD <- as.yearqtr(eco_data_us$TIME_PERIOD, format="%Y-Q%q")


eco_data_wide_us <- eco_data_us %>%
  dplyr::select(TIME_PERIOD, MEASURE, OBS_VALUE) %>%
  tidyr::pivot_wider(
    names_from = MEASURE,   # Les variables comme GDP, GNP deviendront des colonnes
    values_from = OBS_VALUE # Les valeurs associées aux variables
  ) %>%
  dplyr::arrange(TIME_PERIOD)

colnames(eco_data_wide_us) <- ifelse(colnames(eco_data_wide_us) != "TIME_PERIOD", 
                                     paste0(colnames(eco_data_wide_us), "_us"), 
                                     colnames(eco_data_wide_us))
```

ajout des variables des US dans la table de la France : 

```{r}
# Fusionner les deux dataframes sur TIME_PERIOD (en utilisant une jointure gauche pour garder toutes les lignes de eco_data_wide)
eco_data_combined <- merge(eco_data_wide, eco_data_wide_us, by = "TIME_PERIOD", all.x = TRUE)

```


interpolation : 

```{r}
library(dplyr)
library(tidyr)
library(zoo)


eco_data_combined$TIME_PERIOD <- as.yearqtr(eco_data_combined$TIME_PERIOD, format="%Y-Q%q")

# Convertir les trimestres en dates, par exemple en prenant le 1er jour de chaque trimestre
eco_data_combined$DATE <- as.Date(eco_data_combined$TIME_PERIOD)

# Créer une séquence de dates journalières entre la première et la dernière date
date_seq <- seq(from = min(eco_data_combined$DATE), to = max(eco_data_combined$DATE), by = "day")

# Fonction d'interpolation pour chaque colonne
interpolate_column <- function(column_values, date_seq, eco_data) {
  approx_dates <- as.numeric(eco_data$DATE)  # Convertir les dates en numéros pour interpolation
  approx_values <- column_values
  approx_result <- approx(approx_dates, approx_values, xout = as.numeric(date_seq), method = "linear")$y
  return(approx_result)
}

# Créer un dataframe vide pour les dates journalières
eco_data_daily <- data.frame(DATE = date_seq)

# Appliquer l'interpolation sur toutes les colonnes sauf TIME_PERIOD et DATE
for (col in colnames(eco_data_combined)[-c(1, ncol(eco_data_combined))]) {
  eco_data_daily[[col]] <- interpolate_column(eco_data_combined[[col]], date_seq, eco_data_combined)
}

# Afficher les premières lignes du dataframe avec les données journalières interpolées
head(eco_data_daily)
```

obtenir la table pour les prédictions : 

```{r}
eco_data_after_date <- eco_data_daily %>% 
  filter(DATE > as.Date("2024-10-30"))

# Sauvegarder dans un fichier CSV
write.csv(eco_data_after_date, "eco_data_after_2024-10-30.csv", row.names = FALSE)

```


```{r}
cac40_close_df <- data.frame(Date = index(cac40_close), Value = coredata(cac40_close))
colnames(cac40_close_df) <- c("DATE", "CAC40")

# Joindre les valeurs de CAC 40 dans eco_data_daily selon la colonne DATE
eco_data_daily <- left_join(eco_data_daily, cac40_close_df, by = "DATE")

colnames(eco_data_daily)
eco_data_daily_clean <- eco_data_daily[!is.na(eco_data_daily$CAC40), ]
write.csv(eco_data_daily_clean, "eco_data_daily_clean.csv", row.names = FALSE)
```

Chargement de la base de données finale : 

```{r}
final_database <- read_csv("final_database.csv", show_col_types = FALSE)
final_database$Date <- as.Date(final_database$Date)

# Convertir toutes les autres colonnes en numérique
numeric_columns <- setdiff(names(final_database), "Date")  # Sélectionner toutes les colonnes sauf 'Date'
final_database[numeric_columns] <- lapply(final_database[numeric_columns], as.numeric)

```


#Analyses préliminaires 

```{r}
# Check for missing values
missing_values <- sum(is.na(final_database$Close))

# Display the number of missing values
print(paste("Number of missing values:", missing_values))

# If missing values exist, display their dates
if (missing_values > 0) {
  missing_dates <- final_database$Date[is.na(final_database$Close)]
  print("Dates with missing values:")
  print(missing_dates)
} else {
  print("No missing values in the series.")
}

# Descriptive statistics
basicStats(final_database$Close)

# Add a linear trend
ggplot(final_database, aes(x = Date, y = Close)) +
  geom_line(color = "black") + 
  geom_smooth(method = "lm", se = FALSE, color = "red") + 
  ggtitle("Linear Trend of the Index") +
  xlab("Date") +
  ylab("Closing Price") +
  theme_minimal()

# Fit a linear model: Price ~ Time
time <- as.numeric(final_database$Date) # Convert dates to numeric values
lm_model <- lm(final_database$Close ~ time)

# Model summary
summary(lm_model)

# Convert the series to monthly frequency
final_xts <- xts(final_database$Close, order.by = final_database$Date)
final_monthly <- to.monthly(final_xts, indexAt = "lastof", OHLC = FALSE)

# Visualize monthly averages
final_monthly_mean <- aggregate(final_monthly, as.yearmon, mean)

autoplot(final_monthly_mean) +
  ggtitle("Monthly Averages of the Index") +
  xlab("Date") +
  ylab("Monthly Closing Average") +
  theme_minimal()

```

# modèle ARIMA 

Séparation des données en train/test 

```{r}
# Séparer les données en train (avant janvier 2023) et test (après janvier 2023)
train_data <- final_database %>% filter(Date < "2023-01-01")
test_data <- final_database %>% filter(Date >= "2023-01-01")

```

```{r}
acf(train_data$Close)
pacf(train_data$Close)
acf(train_data$Return)
pacf(train_data$Return)
```
#sur les prix de clôture 

```{r}
# Définir les paramètres pour les modèles ARMA
p_values <- 1:6  # Valeurs de p
q_values <- 1:6  # Valeurs de q

# Stocker les modèles et leurs résultats
models <- list()
valid_models <- list()
aic_values <- c()
bic_values <- c()
box_test_results <- list()

# Ajustement des modèles ARMA et vérification de la blancheur des résidus sur l'ensemble train
for (p in p_values) {
  for (q in q_values) {
    model_name <- paste0("ARIMA", p, q)
    
    # Ajuster le modèle ARMA(p, q) sur les train_data$Return
    models[[model_name]] <- arima(train_data$Close, order = c(p, 1, q))
    
    # Récupérer les résidus et effectuer le test de Ljung-Box
    resid <- residuals(models[[model_name]])
    box_test <- Box.test(resid, lag = 30)
    
    # Stocker le résultat du test
    box_test_results[[model_name]] <- box_test
    
    # Si les résidus sont blancs (p-value > 0.05), ajouter à la liste des modèles valides
    if (box_test$p.value > 0.05) {
      valid_models[[model_name]] <- models[[model_name]]
      aic_values[model_name] <- AIC(models[[model_name]])
      bic_values[model_name] <- BIC(models[[model_name]])
    }
  }
}

# Afficher les résultats des tests de blancheur
cat("Résultats des tests de blancheur des résidus (p-value) :\n")
for (model_name in names(box_test_results)) {
  cat(model_name, ": p-value =", box_test_results[[model_name]]$p.value, "\n")
}

# Évaluer les modèles valides uniquement
if (length(valid_models) > 0) {
  cat("\nCritères AIC et BIC pour les modèles valides :\n")
  aic_results <- data.frame(Model = names(aic_values), AIC = aic_values, BIC = bic_values)
  print(aic_results[order(aic_results$AIC), ])  # Trier par AIC

  # Identifier le meilleur modèle parmi les modèles valides
  best_model <- names(which.min(aic_values))
  cat("\nMeilleur modèle basé sur AIC parmi les modèles valides :", best_model, "\n")
} else {
  cat("\nAucun modèle n'a passé le test de blancheur des résidus.\n")
}


```

```{r}
library(ggplot2)
library(dplyr)

# Ajuster le modèle ARIMA(5,1,4) sur l'ensemble d'entraînement
best_arma_model <- arima(train_data$Close, order = c(5, 1, 4))

# Résumé du modèle ARIMA
summary(best_arma_model)

# Faire des prédictions pour l'ensemble d'entraînement (valeurs ajustées)
fitted_train <- train_data$Close - residuals(best_arma_model)

# Créer un data frame pour les vraies valeurs et les prédictions in-sample
plot_data_train <- data.frame(
  Time = train_data$Date,
  Observed = train_data$Close,
  Predicted = fitted_train
)

# Calculer les erreurs sur l'ensemble d'entraînement
errors_train <- plot_data_train$Observed - plot_data_train$Predicted
rmse_train <- sqrt(mean(errors_train^2))
mae_train <- mean(abs(errors_train))

# Afficher les résultats pour l'ensemble d'entraînement
cat("Performance du modèle ARIMA(5,1,4) pour l'ensemble d'entraînement :\n")
cat("RMSE : ", rmse_train, "\n")
cat("MAE : ", mae_train, "\n")

# Ajouter une colonne pour les années et découper par tranches de 5 ans
plot_data_train <- plot_data_train %>%
  mutate(
    Year = as.numeric(format(Time, "%Y")),
    Period = paste0(floor(Year / 5) * 5, "-", floor(Year / 5) * 5 + 4)  # Tranches de 5 ans
  )

# Découper les données en tranches de 5 ans
periods <- unique(plot_data_train$Period)

# Générer un graphique pour chaque tranche de 5 ans
for (period in periods) {
  # Filtrer les données pour la tranche actuelle
  period_data <- filter(plot_data_train, Period == period)
  
  # Générer un graphique pour la tranche actuelle
  p <- ggplot(period_data, aes(x = Time)) +
    geom_line(aes(y = Observed), color = 'black', linewidth = 1) +  # Série observée en noir
    geom_line(aes(y = Predicted), color = 'blue', linewidth = 1) +  # Prédictions en bleu
    labs(
      title = paste("Comparaison des prédictions ARIMA(5,1,4) - Période :", period),
      x = "Date", y = "Valeur Ajustée"
    ) +
    theme_minimal()
  
  # Afficher le graphique
  print(p)
}


# Faire des prédictions sur l'ensemble de test (n.ahead = longueur de test_data)
predictions_test <- predict(best_arma_model, n.ahead = length(test_data$Close))$pred

# Créer un data frame pour les valeurs observées et les prédictions de test
plot_data_test <- data.frame(
  Time = test_data$Date,
  Observed = test_data$Close,
  Predicted = predictions_test
)

# Tracer les vraies valeurs et les prédictions pour l'ensemble de test
ggplot(plot_data_test, aes(x = Time)) +
  geom_line(aes(y = Observed, color = "Observed"), size = 1) +
  geom_line(aes(y = Predicted, color = "Predicted"), linetype = "dashed", size = 1) +
  labs(title = "Prédictions vs Valeurs Réelles - Test", x = "Date", y = "Valeur Ajustée") +
  scale_color_manual(values = c("Observed" = "blue", "Predicted" = "red")) +
  theme_minimal()

# Calculer les erreurs sur l'ensemble de test
errors_test <- plot_data_test$Observed - plot_data_test$Predicted

# Calculer RMSE et MAE pour l'ensemble de test
rmse_test <- sqrt(mean(errors_test^2))
mae_test <- mean(abs(errors_test))

# Afficher les résultats pour l'ensemble de test
cat("Performance du modèle ARIMA(5,1,4) pour l'ensemble de test :\n")
cat("RMSE : ", rmse_test, "\n")
cat("MAE : ", mae_test, "\n")

```





```{r}
library(dplyr)
library(tidyr)
exog <- dplyr::select(train_data, Momentum, Stochastic_K, CCI)

arimax_model <- arima(train_data$Close, order = c(4, 1, 5), xreg = exog)
fitted_arimax <- train_data$Close - residuals(arimax_model)

rmse_arimax <- sqrt(mean(residuals(arimax_model)^2, na.rm = TRUE))
mae_arimax <- mean(abs(residuals(arimax_model)), na.rm = TRUE)
cat("Performance ARIMAX(4,1,5) avec GDP:\n")
cat("RMSE :", rmse_arimax, "\n")
cat("MAE :", mae_arimax, "\n")

# 6. Visualiser les prédictions in-sample
plot_data <- data.frame(
  Time = train_data$Date,  
  Observed = train_data$Close, 
  ARIMAX = fitted_arimax
)

ggplot(plot_data, aes(x = Time)) +
  geom_line(aes(y = Observed, color = "Observed")) +
  geom_line(aes(y = ARIMAX, color = "ARIMAX"), linetype = "dashed") +
  labs(title = "Modèle ARIMAX",
       x = "Date", y = "Close") +
  scale_color_manual(values = c("Observed" = "black", "ARIMAX" = "red")) +
  theme_minimal()


```


```{r}
# Préparer les données exogènes pour l'ensemble de test

exog_test <- dplyr::select(test_data, Momentum, Stochastic_K, CCI)

# Faire des prédictions sur l'ensemble test
predictions_test <- predict(arimax_model, n.ahead = nrow(test_data), newxreg = exog_test)

# Extraire les prédictions
predicted_test <- predictions_test$pred

# Créer un data frame avec les vraies valeurs et les prédictions
plot_data_test <- data.frame(
  Time = test_data$Date,
  Observed = test_data$Close,
  Predicted = predicted_test
)

# Calculer les erreurs
errors_test <- plot_data_test$Observed - plot_data_test$Predicted
rmse_test <- sqrt(mean(errors_test^2))
mae_test <- mean(abs(errors_test))

# Afficher les résultats
cat("Performance ARIMAX(4,1,5) sur l'ensemble test :\n")
cat("RMSE :", rmse_test, "\n")
cat("MAE :", mae_test, "\n")

# Visualiser les résultats
ggplot(plot_data_test, aes(x = Time)) +
  geom_line(aes(y = Observed, color = "Observed")) +
  geom_line(aes(y = Predicted, color = "Predicted"), linetype = "dashed") +
  labs(title = "Prédictions ARIMAX vs Observations - Ensemble Test",
       x = "Date", y = "Close") +
  scale_color_manual(values = c("Observed" = "black", "Predicted" = "red")) +
  theme_minimal()

```

en rajoutant le PIB (différencié pour que ce soit stationnaire):

```{r}
# 1. Créer une copie de train_data pour effectuer la différenciation
train_data_diff <- train_data %>%
  mutate(
    GDPV_diff = c(NA, diff(GDPV)),  # Différenciation de GDPV
    CPIH_YTYPCT_diff = c(NA, diff(CPIH_YTYPCT)),  # Différenciation de CPIH_YTYPCT
    UNR_us_diff = c(NA, diff(UNR_us))  # Différenciation de UNR_us
  )  # Différenciation des variables I(1)

# 2. Préparer les variables exogènes avec les trois variables différenciées
exog_train <- train_data_diff %>%
  dplyr::select(GDPV_diff) %>%  # Sélectionner uniquement la colonne GDPV_diff
  dplyr::filter(!is.na(GDPV_diff))  # Supprimer les lignes où GDPV_diff est NA

# 3. Ajuster le modèle ARIMAX sur train_data en utilisant les variables exogènes modifiées
arimax_model <- arima(train_data$Close[2:nrow(train_data)], order = c(4, 1, 5), xreg = exog_train)

# 4. Prédictions in-sample (ensemble d'entraînement)
fitted_arimax <- train_data$Close[2:nrow(train_data)] - residuals(arimax_model)

# 5. Calcul des métriques pour l'ensemble d'entraînement
rmse_arimax <- sqrt(mean(residuals(arimax_model)^2, na.rm = TRUE))
mae_arimax <- mean(abs(residuals(arimax_model)), na.rm = TRUE)

# 6. Affichage des performances
cat("Performance ARIMAX(4,1,5) avec GDPV_diff, CPIH_YTYPCT_diff et UNR_us_diff:\n")
cat("RMSE :", rmse_arimax, "\n")
cat("MAE :", mae_arimax, "\n")

# 7. Visualiser les prédictions in-sample
plot_data_train <- data.frame(
  Time = train_data$Date[2:nrow(train_data)],  
  Observed = train_data$Close[2:nrow(train_data)], 
  ARIMAX = fitted_arimax
)

ggplot(plot_data_train, aes(x = Time)) +
  geom_line(aes(y = Observed, color = "Observed")) +
  geom_line(aes(y = ARIMAX, color = "ARIMAX"), linetype = "dashed") +
  labs(title = "Modèle ARIMAX avec GDPV_diff, CPIH_YTYPCT_diff et UNR_us_diff",
       x = "Date", y = "Close") +
  scale_color_manual(values = c("Observed" = "black", "ARIMAX" = "red")) +
  theme_minimal()

# --------------------------------
# Prédictions sur l'ensemble de test
# --------------------------------

# 1. Créer une copie de test_data pour effectuer la différenciation
test_data_diff <- test_data %>%
  mutate(
    GDPV_diff = c(NA, diff(GDPV)),  # Différenciation de GDPV
    CPIH_YTYPCT_diff = c(NA, diff(CPIH_YTYPCT)),  # Différenciation de CPIH_YTYPCT
    UNR_us_diff = c(NA, diff(UNR_us))  # Différenciation de UNR_us
  )

# 2. Préparer les variables exogènes avec les trois variables différenciées pour l'ensemble de test

exog_test <- test_data_diff %>%
  dplyr::select(GDPV_diff) %>%  # Sélectionner uniquement la colonne GDPV_diff
  dplyr::filter(!is.na(GDPV_diff))  # Supprimer les lignes où GDPV_diff est NA
# 3. Prédictions sur l'ensemble de test
predictions_test <- predict(arimax_model, n.ahead = nrow(exog_test), newxreg = exog_test)$pred

# 4. Créer le dataframe des prédictions
plot_data_test <- data.frame(
  Time = test_data$Date[2:nrow(test_data)],
  Observed = test_data$Close[2:nrow(test_data)],
  Predicted = predictions_test
)

# 5. Visualisation des prédictions sur l'ensemble de test
ggplot(plot_data_test, aes(x = Time)) +
  geom_line(aes(y = Observed, color = "Observed")) +
  geom_line(aes(y = Predicted, color = "Predicted"), linetype = "dashed") +
  labs(title = "Prédictions ARIMAX sur l'ensemble de test",
       x = "Date", y = "Close") +
  scale_color_manual(values = c("Observed" = "black", "Predicted" = "red")) +
  theme_minimal()

# 6. Calculer les erreurs pour l'ensemble de test
errors_test <- plot_data_test$Observed - plot_data_test$Predicted

# 7. Calculer RMSE et MAE pour l'ensemble de test
rmse_test <- sqrt(mean(errors_test^2))
mae_test <- mean(abs(errors_test))

# 8. Afficher les résultats pour l'ensemble de test
cat("Performance du modèle ARIMAX sur l'ensemble de test :\n")
cat("RMSE :", rmse_test, "\n")
cat("MAE :", mae_test, "\n")

```

```{r}
# 1. Préparer les variables exogènes avec les séries non différenciées
exog_train <- train_data %>%
  dplyr::select(Stochastic_K) %>%  # Sélectionner uniquement la colonne Stochastic_K
  dplyr::filter(!is.na(Stochastic_K))  # Supprimer les lignes où Stochastic_K est NA


# 2. Ajuster le modèle ARIMAX sur train_data en utilisant les variables exogènes non différenciées
arimax_model <- arima(train_data$Close, order = c(4, 1, 5), xreg = exog_train)

# 3. Prédictions in-sample pour l'ensemble d'entraînement
fitted_arimax <- train_data$Close - residuals(arimax_model)

# 4. Calcul des métriques pour l'ensemble d'entraînement
rmse_arimax <- sqrt(mean(residuals(arimax_model)^2, na.rm = TRUE))
mae_arimax <- mean(abs(residuals(arimax_model)), na.rm = TRUE)

# 5. Affichage des performances
cat("Performance ARIMAX(4,1,5) avec GDPV, CPIH_YTYPCT et UNR_us:\n")
cat("RMSE :", rmse_arimax, "\n")
cat("MAE :", mae_arimax, "\n")

# 6. Visualiser les prédictions in-sample
plot_data_train <- data.frame(
  Time = train_data$Date,  # Pas besoin d'exclure la première ligne ici
  Observed = train_data$Close, 
  ARIMAX = fitted_arimax
)

ggplot(plot_data_train, aes(x = Time)) +
  geom_line(aes(y = Observed, color = "Observed")) +
  geom_line(aes(y = ARIMAX, color = "ARIMAX"), linetype = "dashed") +
  labs(title = "Modèle ARIMAX avec GDPV, CPIH_YTYPCT et UNR_us",
       x = "Date", y = "Close") +
  scale_color_manual(values = c("Observed" = "black", "ARIMAX" = "red")) +
  theme_minimal()

# --------------------------------
# Prédictions sur l'ensemble de test
# --------------------------------

# 1. Préparer les variables exogènes avec les séries non différenciées pour l'ensemble de test
exog_test <- test_data %>%
  dplyr::select(Stochastic_K) %>%  # Sélectionner uniquement la colonne Stochastic_K
  dplyr::filter(!is.na(Stochastic_K))  # Supprimer les lignes où Stochastic_K est NA


# 2. Prédictions sur l'ensemble de test
predictions_test <- predict(arimax_model, n.ahead = nrow(exog_test), newxreg = exog_test)$pred

# 3. Créer le dataframe des prédictions
plot_data_test <- data.frame(
  Time = test_data$Date,
  Observed = test_data$Close,
  Predicted = predictions_test
)

# 4. Visualisation des prédictions sur l'ensemble de test
ggplot(plot_data_test, aes(x = Time)) +
  geom_line(aes(y = Observed, color = "Observed")) +
  geom_line(aes(y = Predicted, color = "Predicted"), linetype = "dashed") +
  labs(title = "Prédictions ARIMAX sur l'ensemble de test",
       x = "Date", y = "Close") +
  scale_color_manual(values = c("Observed" = "black", "Predicted" = "red")) +
  theme_minimal()

# 5. Calculer les erreurs pour l'ensemble de test
errors_test <- plot_data_test$Observed - plot_data_test$Predicted

# 6. Calculer RMSE et MAE pour l'ensemble de test
rmse_test <- sqrt(mean(errors_test^2))
mae_test <- mean(abs(errors_test))

# 7. Afficher les résultats pour l'ensemble de test
cat("Performance du modèle ARIMAX sur l'ensemble de test :\n")
cat("RMSE :", rmse_test, "\n")
cat("MAE :", mae_test, "\n")

```


# sur les log returns 

```{r}
# Définir les paramètres pour les modèles ARMA
p_values <- 1:6  # Valeurs de p
q_values <- 1:6  # Valeurs de q

# Stocker les modèles et leurs résultats
models <- list()
valid_models <- list()
aic_values <- c()
bic_values <- c()
box_test_results <- list()

# Ajustement des modèles ARMA et vérification de la blancheur des résidus sur l'ensemble train
for (p in p_values) {
  for (q in q_values) {
    model_name <- paste0("ARMA", p, q)
    
    # Ajuster le modèle ARMA(p, q) sur les train_data$Return
    models[[model_name]] <- arima(train_data$Return, order = c(p, 0, q))
    
    # Récupérer les résidus et effectuer le test de Ljung-Box
    resid <- residuals(models[[model_name]])
    box_test <- Box.test(resid, lag = 30)
    
    # Stocker le résultat du test
    box_test_results[[model_name]] <- box_test
    
    # Si les résidus sont blancs (p-value > 0.05), ajouter à la liste des modèles valides
    if (box_test$p.value > 0.05) {
      valid_models[[model_name]] <- models[[model_name]]
      aic_values[model_name] <- AIC(models[[model_name]])
      bic_values[model_name] <- BIC(models[[model_name]])
    }
  }
}

# Afficher les résultats des tests de blancheur
cat("Résultats des tests de blancheur des résidus (p-value) :\n")
for (model_name in names(box_test_results)) {
  cat(model_name, ": p-value =", box_test_results[[model_name]]$p.value, "\n")
}

# Évaluer les modèles valides uniquement
if (length(valid_models) > 0) {
  cat("\nCritères AIC et BIC pour les modèles valides :\n")
  aic_results <- data.frame(Model = names(aic_values), AIC = aic_values, BIC = bic_values)
  print(aic_results[order(aic_results$AIC), ])  # Trier par AIC

  # Identifier le meilleur modèle parmi les modèles valides
  best_model <- names(which.min(aic_values))
  cat("\nMeilleur modèle basé sur AIC parmi les modèles valides :", best_model, "\n")
} else {
  cat("\nAucun modèle n'a passé le test de blancheur des résidus.\n")
}

```

```{r}
library(ggplot2)
library(dplyr)

arma_model <- arima(train_data$Return, order = c(2, 0, 5))

# Faire des prédictions in-sample (valeurs ajustées)
fitted_train <- train_data$Return - residuals(arma_model)

# Préparer les données pour ggplot
plot_data_train <- data.frame(
  Time = train_data$Date,  # Exclure la première ligne (log diff)
  Observed = train_data$Return,   # Série log_returns
  Predicted = fitted_train        # Prédictions du modèle ARMA
)

# Ajouter une colonne pour grouper les années par tranches de 5 ans
plot_data_train <- plot_data_train %>%
  mutate(
    Year = as.numeric(format(Time, "%Y")),  # Extraire l'année
    Period = paste0(floor(Year / 5) * 5, "-", floor(Year / 5) * 5 + 4)  # Grouper par tranches de 5 ans
  )

# Identifier toutes les tranches de 5 ans
periods <- unique(plot_data_train$Period)

# Générer un graphique pour chaque tranche de 5 ans
for (period in periods) {
  # Filtrer les données pour la tranche actuelle
  period_data <- filter(plot_data_train, Period == period)
  
  # Créer le graphique
  p <- ggplot(period_data, aes(x = Time)) +
    geom_line(aes(y = Observed), color = 'black', linewidth = 1) +  # Série observée en noir
    geom_line(aes(y = Predicted), color = 'blue', linewidth = 1) +  # Prédictions en bleu
    labs(
      title = paste("Comparaison des prédictions ARMA - Période :", period),
      x = "Date", 
      y = "Log-Returns"
    ) +
    theme_minimal() +
    theme(legend.position = "none")
  
  # Afficher le graphique
  print(p)
}

# Performance globale sur l'ensemble train
errors_train <- plot_data_train$Observed - plot_data_train$Predicted
rmse_train <- sqrt(mean(errors_train^2))
mae_train <- mean(abs(errors_train))

cat("Performance globale sur l'ensemble train:\n")
cat("RMSE: ", rmse_train, "\n")
cat("MAE: ", mae_train, "\n")

# Analyse pour octobre 2008
subsample_month_train <- filter(plot_data_train, Year == 2008 & format(Time, "%m") == "10")
errors_month_train <- subsample_month_train$Observed - subsample_month_train$Predicted
rmse_month_train <- sqrt(mean(errors_month_train^2))
mae_month_train <- mean(abs(errors_month_train))

cat("Performance pour octobre 2008:\n")
cat("RMSE: ", rmse_month_train, "\n")
cat("MAE: ", mae_month_train, "\n")

```
==> comme les prédictions sont toujours nulles et qu'on fait une moyenne sur beaucoup d'échantillons, les irrégularités sont vite effacées et on obtient un MAE très faible (attention à l'échelle, car ce sont des log returns). Par ailleurs, si on observe sur un mois précis (crise de 2008 par exemple), on observe que les métriques de performance changent grandement. 
Par ailleurs, les prédictions sont toujours retardées (c'est induit par le modèle que l'on choisit), et d'intensité faible. 


On vérifie les performances sur l'ensemble test : 

```{r}
library(forecast)
library(ggplot2)
library(dplyr)

# 1. Prédictions in-sample sur l'ensemble test avec le modèle ARMA
forecast_result <- forecast(arma_model, h = length(test_data$Return))

# 2. Extraire les prédictions
predictions_test <- forecast_result$mean

# 3. Préparer les données pour ggplot pour l'ensemble test
plot_data_test <- data.frame(
  Time = test_data$Date,
  Observed = test_data$Return,
  Predicted = predictions_test
)

# 4. Transformation en prix de clôture
# Dernier prix de clôture connu (fin de l'ensemble train)
last_train_price <- 6473.76  # Remplacez par le prix de clôture réel si nécessaire

plot_data_test <- plot_data_test %>%
  mutate(
    Observed_Price = last_train_price * cumprod(exp(Observed)),  # Transformation des log-returns observés
    Predicted_Price = last_train_price * cumprod(exp(Predicted))  # Transformation des log-returns prédites
  )

# 5. Calcul des erreurs pour les prix
errors_test <- plot_data_test$Observed_Price - plot_data_test$Predicted_Price

# Calcul des métriques : RMSE et MAE pour l'ensemble test
rmse_test <- sqrt(mean(errors_test^2, na.rm = TRUE))
mae_test <- mean(abs(errors_test), na.rm = TRUE)

# Afficher les résultats pour l'ensemble test
cat("Performance du modèle ARMA sur les prix de clôture pour l'ensemble test:\n")
cat("RMSE (Prix): ", rmse_test, "\n")
cat("MAE (Prix): ", mae_test, "\n")

# 7. Graphique des prix de clôture
ggplot(plot_data_test, aes(x = Time)) +
  geom_line(aes(y = Observed_Price, color = "Observed Price"), linewidth = 1) +  # Prix observés en noir
  geom_line(aes(y = Predicted_Price, color = "Predicted Price"), linewidth = 1) +  # Prix prédit en bleu
  labs(title = "Prédictions ARMA sur les prix de clôture (ensemble test)",
       x = "Date", y = "Prix de clôture") +
  scale_color_manual(values = c("Observed Price" = "black", "Predicted Price" = "blue")) +
  theme_minimal()

```

```{r}
library(dplyr)
library(forecast)
library(ggplot2)

# 1. Préparation des données exogènes pour l'ensemble d'entraînement
exog_train <- train_data %>%
  dplyr::select(GDPV) %>%
  mutate(GDPV_diff = c(NA, diff(GDPV))) %>%  # Calcul de la différence
  dplyr::filter(!is.na(GDPV_diff))  # Supprimer les lignes avec NA

# Ajuster Return pour correspondre aux données disponibles
dependent_var_train <- train_data$Return[-1]  # Enlever la première observation pour aligner avec diff

# 2. Ajustement du modèle ARMAX
armax_model <- arima(
  dependent_var_train,  # Log-returns comme variable dépendante
  order = c(2, 0, 5),  # Paramètres ARIMA(p, d, q)
  xreg = exog_train$GDPV_diff  # Variable exogène différenciée
)

# 3. Évaluation des résidus
residuals_armax <- residuals(armax_model)
Box.test(residuals_armax, lag = 30, type = "Ljung-Box")  # Test de blancheur des résidus

# 4. Préparation des données exogènes pour l'ensemble de test
exog_test <- test_data %>%
  dplyr::select(GDPV) %>%
  mutate(GDPV_diff = c(NA, diff(GDPV))) %>%  # Calcul de la différence
  dplyr::filter(!is.na(GDPV_diff))  # Supprimer les lignes avec NA

# Ajuster les données observées pour l'ensemble de test
dependent_var_test <- test_data$Return[-1]  # Aligner avec les valeurs différenciées

# 5. Prédictions sur l'ensemble de test
predictions_test <- predict(
  armax_model,
  n.ahead = nrow(exog_test),
  newxreg = exog_test$GDPV_diff
)$pred

# 6. Transformation des log-returns en prix de clôture
# Dernier prix de clôture connu (fin de l'ensemble train)
last_train_price <- 6473.76  

# Créer un DataFrame combiné pour visualisation
plot_data_test <- data.frame(
  Time = test_data$Date[-1],  # Ajustement pour les valeurs différenciées
  Observed = dependent_var_test,
  Predicted = predictions_test
)

# Transformation en prix de clôture
plot_data_test <- plot_data_test %>%
  mutate(
    Observed_Price = last_train_price * cumprod(exp(Observed)),  # Prix observés
    Predicted_Price = last_train_price * cumprod(exp(Predicted))  # Prix prédits
  )

# 7. Visualisation des résultats en prix
ggplot(plot_data_test, aes(x = Time)) +
  geom_line(aes(y = Observed_Price, color = "Observed Price")) +
  geom_line(aes(y = Predicted_Price, color = "Predicted Price"), linetype = "dashed") +
  labs(title = "Prix de clôture observés vs prédits avec GDPV différencié",
       x = "Date", y = "Prix de clôture") +
  scale_color_manual(values = c("Observed Price" = "black", "Predicted Price" = "blue")) +
  theme_minimal()

# 8. Calcul des erreurs sur les prix
errors_prices <- plot_data_test$Observed_Price - plot_data_test$Predicted_Price

# Calcul des métriques d'erreur : RMSE et MAE
rmse_prices <- sqrt(mean(errors_prices^2, na.rm = TRUE))  # RMSE
mae_prices <- mean(abs(errors_prices), na.rm = TRUE)      # MAE

# Affichage des performances
cat("Performance sur les prix de clôture :\n")
cat("RMSE (Prix): ", rmse_prices, "\n")
cat("MAE (Prix): ", mae_prices, "\n")

```

combinaison des variables I(1) 

```{r}
library(dplyr)
library(forecast)
library(ggplot2)
library(combinat)

# Liste des variables I(1)
variables_I1 <- c("GDPV", "CPIH_YTYPCT", "UNR_us", "High_minus_Low", "SMA_5",
                  "SMA_10", "SMA_20", "WMA_5", "WMA_10", "WMA_20", "RSI", "Williams_R", "MACD")

# Fonction pour préparer les données différenciées
prepare_diff_data <- function(data, vars) {
  data %>%
    dplyr::select(all_of(vars)) %>%
    mutate(across(everything(), ~ c(NA, diff(.)))) %>%
    filter(complete.cases(.))
}

# Initialiser les résultats
results <- data.frame(Combination = character(), RMSE = numeric(), MAE = numeric(), stringsAsFactors = FALSE)

# Tester toutes les combinaisons de 1 à 3 variables
combinations <- unlist(lapply(1:4, function(k) combn(variables_I1, k, simplify = FALSE)), recursive = FALSE)

# Dernier prix connu pour transformer en prix de clôture
last_train_price <- 6473.76

# Boucle sur chaque combinaison
for (comb in combinations) {
  # Préparer les données différenciées pour train et test
  exog_train <- prepare_diff_data(train_data, comb)
  exog_test <- prepare_diff_data(test_data, comb)
  
  # Sauter si les données exogènes ne correspondent pas en taille
  if (nrow(exog_train) != nrow(train_data) - 1 || nrow(exog_test) != nrow(test_data) - 1) next
  
  # Ajuster la variable dépendante
  dependent_var_train <- train_data$Return[-1]
  
  # Ajuster le modèle ARMAX
  armax_model <- tryCatch(
    arima(dependent_var_train, order = c(2, 0, 5), xreg = as.matrix(exog_train)),
    error = function(e) NULL
  )
  
  # Vérifier si le modèle a été correctement ajusté
  if (is.null(armax_model)) next
  
  # Prédictions sur l'ensemble de test
  predictions_test <- tryCatch(
    predict(armax_model, n.ahead = nrow(exog_test), newxreg = as.matrix(exog_test))$pred,
    error = function(e) NULL
  )
  
  # Vérifier si les prédictions ont été effectuées
  if (is.null(predictions_test)) next
  
  # Transformation en prix de clôture
  observed_prices <- last_train_price * cumprod(exp(test_data$Return[-1]))
  predicted_prices <- last_train_price * cumprod(exp(predictions_test))
  
  # Calcul des erreurs
  errors_prices <- observed_prices - predicted_prices
  rmse <- sqrt(mean(errors_prices^2, na.rm = TRUE))
  mae <- mean(abs(errors_prices), na.rm = TRUE)
  
  # Ajouter les résultats
  results <- rbind(results, data.frame(
    Combination = paste(comb, collapse = ", "),
    RMSE = rmse,
    MAE = mae,
    stringsAsFactors = FALSE
  ))
}

# Identifier le meilleur modèle
best_model <- results[which.min(results$RMSE), ]

# Afficher les résultats
cat("Meilleur modèle trouvé :\n")
print(best_model)

# Afficher tous les résultats triés par RMSE
results <- results[order(results$RMSE), ]
print(head(results, 20))  # Top 10 modèles

```

```{r}
# Graphique pour le meilleur modèle trouvé

# Extraire les variables de la meilleure combinaison
best_combination_vars <- unlist(strsplit(best_model$Combination, ", "))

# Préparer les données différenciées pour la meilleure combinaison
exog_train_best <- prepare_diff_data(train_data, best_combination_vars)
exog_test_best <- prepare_diff_data(test_data, best_combination_vars)

# Ajuster la variable dépendante
dependent_var_train_best <- train_data$Return[-1]

# Ajuster le modèle ARMAX pour la meilleure combinaison
armax_model_best <- arima(
  dependent_var_train_best,
  order = c(2, 0, 5),
  xreg = as.matrix(exog_train_best)
)

# Prédictions sur l'ensemble de test pour le meilleur modèle
predictions_test_best <- predict(
  armax_model_best,
  n.ahead = nrow(exog_test_best),
  newxreg = as.matrix(exog_test_best)
)$pred

# Transformation des log-returns en prix de clôture
last_train_price <- 6473.76  # Dernier prix connu
observed_prices_best <- last_train_price * cumprod(exp(test_data$Return[-1]))
predicted_prices_best <- last_train_price * cumprod(exp(predictions_test_best))

# Préparer les données pour le graphique
plot_data_test_best <- data.frame(
  Time = test_data$Date[-1],
  Observed_Price = observed_prices_best,
  Predicted_Price = predicted_prices_best
)

# Générer le graphique
ggplot(plot_data_test_best, aes(x = Time)) +
  geom_line(aes(y = Observed_Price, color = "Observed Price")) +
  geom_line(aes(y = Predicted_Price, color = "Predicted Price"), linetype = "dashed") +
  labs(
    title = paste("Meilleur modèle ARMAX avec les variables :", best_model$Combination),
    x = "Date",
    y = "Prix de clôture"
  ) +
  scale_color_manual(values = c("Observed Price" = "black", "Predicted Price" = "blue")) +
  theme_minimal()

```


```{r}
library(dplyr)
library(forecast)
library(ggplot2)

# Variables I(0)
variables_I0 <- c("Close_minus_Open", "Momentum", "Stochastic_K", "Stochastic_D", "CCI")

# Meilleures combinaisons I(1) identifiées
best_combinations_I1 <- list(
  c("High_minus_Low", "SMA_5", "WMA_5"),
  c("High_minus_Low", "SMA_5", "WMA_5", "MACD"),
  c("SMA_5", "MACD"),
  c("SMA_5", "RSI", "Williams_R", "MACD"),
  c("SMA_5", "WMA_5", "Williams_R"),
  c("SMA_5", "WMA_5", "RSI", "Williams_R"),
  c("SMA_5", "WMA_5", "MACD"),
  c("SMA_5", "WMA_5", "Williams_R", "MACD"),
  c("SMA_5"),
  c("High_minus_Low", "SMA_5", "WMA_5", "RSI")
)

# Préparer les données différenciées
prepare_diff_data <- function(data, vars) {
  data %>%
    dplyr::select(all_of(vars)) %>%
    mutate(across(everything(), ~ c(NA, diff(.)))) %>%
    filter(complete.cases(.))
}

# Dernier prix connu pour la conversion en prix de clôture
last_train_price <- 6473.76

# Initialiser les résultats
results <- data.frame(Combination = character(), RMSE = numeric(), MAE = numeric(), stringsAsFactors = FALSE)

# Tester les combinaisons enrichies
for (comb_I1 in best_combinations_I1) {
  for (k in 1:2) {  # Ajouter 1 ou 2 variables I(0)
    comb_I0 <- combn(variables_I0, k, simplify = FALSE)
    
    for (extra_vars in comb_I0) {
      # Combinaison totale
      total_combination <- c(comb_I1, extra_vars)
      
      # Préparer les données pour train et test
      exog_train <- prepare_diff_data(train_data, total_combination)
      exog_test <- prepare_diff_data(test_data, total_combination)
      
      # Sauter si tailles incompatibles
      if (nrow(exog_train) != nrow(train_data) - 1 || nrow(exog_test) != nrow(test_data) - 1) next
      
      # Ajuster la variable dépendante
      dependent_var_train <- train_data$Return[-1]
      
      # Ajuster le modèle ARMAX
      armax_model <- tryCatch(
        arima(dependent_var_train, order = c(2, 0, 5), xreg = as.matrix(exog_train)),
        error = function(e) NULL
      )
      
      # Vérifier si le modèle a été correctement ajusté
      if (is.null(armax_model)) next
      
      # Prédictions sur l'ensemble de test
      predictions_test <- tryCatch(
        predict(armax_model, n.ahead = nrow(exog_test), newxreg = as.matrix(exog_test))$pred,
        error = function(e) NULL
      )
      
      # Vérifier si les prédictions sont disponibles
      if (is.null(predictions_test)) next
      
      # Transformation en prix de clôture
      observed_prices <- last_train_price * cumprod(exp(test_data$Return[-1]))
      predicted_prices <- last_train_price * cumprod(exp(predictions_test))
      
      # Calcul des erreurs
      errors_prices <- observed_prices - predicted_prices
      rmse <- sqrt(mean(errors_prices^2, na.rm = TRUE))
      mae <- mean(abs(errors_prices), na.rm = TRUE)
      
      # Ajouter les résultats
      results <- rbind(results, data.frame(
        Combination = paste(total_combination, collapse = ", "),
        RMSE = rmse,
        MAE = mae,
        stringsAsFactors = FALSE
      ))
    }
  }
}

# Identifier le meilleur modèle
best_model <- results[which.min(results$RMSE), ]

# Afficher les résultats
cat("Meilleur modèle enrichi trouvé :\n")
print(best_model)

# Top 10 des modèles
results <- results[order(results$RMSE), ]
print(head(results, 10))

# Visualisation pour le meilleur modèle
best_combination <- unlist(strsplit(best_model$Combination, ", "))
exog_train_best <- prepare_diff_data(train_data, best_combination)
exog_test_best <- prepare_diff_data(test_data, best_combination)

# Ajuster le modèle pour le meilleur
dependent_var_train <- train_data$Return[-1]
best_armax_model <- arima(
  dependent_var_train, order = c(2, 0, 5), xreg = as.matrix(exog_train_best)
)
predictions_test_best <- predict(
  best_armax_model, n.ahead = nrow(exog_test_best), newxreg = as.matrix(exog_test_best)
)$pred

# Transformation en prix de clôture
plot_data_best <- data.frame(
  Time = test_data$Date[-1],
  Observed_Price = last_train_price * cumprod(exp(test_data$Return[-1])),
  Predicted_Price = last_train_price * cumprod(exp(predictions_test_best))
)

# Graphique
ggplot(plot_data_best, aes(x = Time)) +
  geom_line(aes(y = Observed_Price, color = "Observed Price")) +
  geom_line(aes(y = Predicted_Price, color = "Predicted Price"), linetype = "dashed") +
  labs(title = "Prix observés vs prédits pour le meilleur modèle enrichi",
       x = "Date", y = "Prix de clôture") +
  scale_color_manual(values = c("Observed Price" = "black", "Predicted Price" = "blue")) +
  theme_minimal()

```

```{r}
library(dplyr)
library(forecast)
library(ggplot2)

# 1. Préparation des données exogènes pour l'ensemble d'entraînement
exog_train <- train_data %>%
  dplyr::select(Stochastic_K) %>%  # Sélectionner uniquement Stochastic_K
  dplyr::filter(!is.na(Stochastic_K))  # Supprimer les lignes avec NA

# Ajuster Return pour correspondre aux données disponibles
dependent_var_train <- train_data$Return[!is.na(train_data$Stochastic_K)]  # Aligner avec exog_train

# 2. Ajustement du modèle ARMAX
armax_model <- arima(
  dependent_var_train,  # Log-returns comme variable dépendante
  order = c(2, 0, 5),  # Paramètres ARIMA(p, d, q)
  xreg = exog_train$Stochastic_K  # Variable exogène
)

# 3. Évaluation des résidus
residuals_armax <- residuals(armax_model)
Box.test(residuals_armax, lag = 30, type = "Ljung-Box")  # Test de blancheur des résidus

# 4. Préparation des données exogènes pour l'ensemble de test
exog_test <- test_data %>%
  dplyr::select(Stochastic_K) %>%
  dplyr::filter(!is.na(Stochastic_K))  # Supprimer les lignes avec NA

# Ajuster les données observées pour l'ensemble de test
dependent_var_test <- test_data$Return[!is.na(test_data$Stochastic_K)]  # Aligner avec exog_test

# 5. Prédictions sur l'ensemble de test
predictions_test <- predict(
  armax_model,
  n.ahead = nrow(exog_test),
  newxreg = exog_test$Stochastic_K
)$pred

# 6. Transformation des log-returns en prix de clôture
# Dernier prix de clôture connu (fin de l'ensemble train)
last_train_price <- 6473.76  # Remplacez par le prix correct si nécessaire

# Créer un DataFrame combiné pour visualisation
plot_data_test <- data.frame(
  Time = test_data$Date[!is.na(test_data$Stochastic_K)],  # Ajustement pour les valeurs non-NA
  Observed = dependent_var_test,
  Predicted = predictions_test
)

# Transformation en prix de clôture
plot_data_test <- plot_data_test %>%
  mutate(
    Observed_Price = last_train_price * cumprod(exp(Observed)),  # Prix observés
    Predicted_Price = last_train_price * cumprod(exp(Predicted))  # Prix prédits
  )

# 7. Visualisation des résultats en prix
ggplot(plot_data_test, aes(x = Time)) +
  geom_line(aes(y = Observed_Price, color = "Observed Price")) +
  geom_line(aes(y = Predicted_Price, color = "Predicted Price"), linetype = "dashed") +
  labs(title = "Prix de clôture observés vs prédits avec Stochastic_K",
       x = "Date", y = "Prix de clôture") +
  scale_color_manual(values = c("Observed Price" = "black", "Predicted Price" = "blue")) +
  theme_minimal()

# 8. Calcul des erreurs sur les prix
errors_prices <- plot_data_test$Observed_Price - plot_data_test$Predicted_Price

# Calcul des métriques d'erreur : RMSE et MAE
rmse_prices <- sqrt(mean(errors_prices^2, na.rm = TRUE))  # RMSE
mae_prices <- mean(abs(errors_prices), na.rm = TRUE)      # MAE

# Affichage des performances
cat("Performance sur les prix de clôture :\n")
cat("RMSE (Prix): ", rmse_prices, "\n")
cat("MAE (Prix): ", mae_prices, "\n")

```




# modèle ARDL sur prix de clôture

Vérification de l'ordre de statio des variables : 


```{r}

# Charger les packages nécessaires
if (!require(tseries)) install.packages("tseries")
library(tseries)

# Supprimer les colonnes non numériques de final_database
df_numeric <- final_database[, sapply(final_database, is.numeric)]

# Initialiser un tableau pour stocker les résultats
stationarity_results_kpss <- data.frame(
  Variable = colnames(df_numeric),
  p_value_Level = NA,  # p-valeur pour la stationnarité en niveau
  p_value_Diff = NA,   # p-valeur pour la stationnarité après différenciation
  Stationarity = NA    # Classification finale : Stationnaire ou Non-stationnaire
)

# Boucle pour tester chaque variable
for (i in 1:ncol(df_numeric)) {
  var_name <- colnames(df_numeric)[i]
  variable <- df_numeric[[var_name]]
  
  # Test KPSS sur la série en niveau
  kpss_level <- kpss.test(na.omit(variable), null = "Level")
  p_value_level <- kpss_level$p.value
  
  # Test KPSS sur la série différenciée
  diff_variable <- diff(variable, differences = 1)
  kpss_diff <- kpss.test(na.omit(diff_variable), null = "Level")
  p_value_diff <- kpss_diff$p.value
  
  # Déterminer le statut de stationnarité
  if (p_value_level > 0.05) {
    status <- "I(0)"
  } else if (p_value_diff > 0.05) {
    status <- "I(1)"
  } else {
    status <- "I(2)"
  }
  
  # Ajouter les résultats au tableau
  stationarity_results_kpss[i, ] <- c(var_name, p_value_level, p_value_diff, status)
}

# Afficher les résultats
print(stationarity_results_kpss)



```

Pour le modèle ARDL, on ne garde que les variables I(0) ou I(1)


```{r}

i0_i1_vars <- stationarity_results_kpss$Variable[
  stationarity_results_kpss$Stationarity %in% c("I(0)", "I(1)")
]

# Vérifier les noms pour s'assurer qu'ils correspondent
i0_i1_vars <- intersect(colnames(final_database), i0_i1_vars)

# Filtrer les colonnes correspondantes dans le DataFrame original
filtered_df <- final_database[, c("Date", i0_i1_vars), drop = FALSE]
```


Calcul de la corrélation avec la cible : 


```{r}
cor_with_target <- cor(
  filtered_df$Close, 
  filtered_df[, !(names(filtered_df) %in% c("Close", "Date"))], 
  use = "complete.obs"
)

cor_with_target

#on ne garde que les variables qui ont une corrélation inférieure à 0.99 ou supérieure à 0.1) 
cols_to_keep <- c("Date", "Close", 
                  "GDPV", "CPIH_YTYPCT", "UNR_us", 
                  "High_minus_Low", 
                  "Momentum", "RSI", "MACD")

# Créer filtered_df avec les colonnes sélectionnées
filtered_df <- filtered_df[, cols_to_keep]

```

Calcul de la matrice de corrélation (pour vérifier les corrélations entre les variables)

```{r}
library(corrplot)
cor_matrix <- cor(filtered_df[, -which(names(filtered_df) == "Date")], use = "complete.obs")

corrplot(cor_matrix, 
         method = "color",    # Affichage sous forme de couleur
         col = colorRampPalette(c("red", "white", "blue"))(200), # Palette de couleurs (rouge à bleu)
         type = "full",       # Afficher toute la matrice
         diag = FALSE,        # Ne pas afficher la diagonale
         addCoef.col = "black",  # Ajouter les coefficients de corrélation en noir
         number.cex = 0.7,    # Taille du texte des coefficients
         tl.cex = 0.8,        # Taille du texte des noms des variables
         tl.col = "black",    # Couleur du texte des noms des variables
         mar = c(0, 0, 1, 0)  # Ajustement des marges
)
```

Test de Granger bilatéral : 

```{r}
# Charger la bibliothèque nécessaire
library(lmtest)

# Liste des variables explicatives (exclure "Date" et "Close")
variables <- colnames(filtered_df)[!(colnames(filtered_df) %in% c("Date", "Close"))]

# Stocker les résultats bilatéraux
bilateral_results <- list()

# Tester la causalité de Granger dans les deux directions
for (var in variables) {
  cat("\n--- Test de Granger entre Close et", var, "---\n")
  
  # 1. Est-ce que la variable explicative Granger-cause la cible ?
  test1 <- grangertest(filtered_df$Close ~ filtered_df[[var]], order = 1)
  
  # 2. Est-ce que la cible Granger-cause la variable explicative ?
  test2 <- grangertest(filtered_df[[var]] ~ filtered_df$Close, order = 1)
  
  # Stocker les résultats
  bilateral_results[[var]] <- list(
    "Variable -> Cible" = test1,
    "Cible -> Variable" = test2
  )
  
  # Afficher les résultats
  cat("\n---", var, "Granger-cause Close ---\n")
  print(test1)
  cat("\n--- Close Granger-cause", var, "---\n")
  print(test2)
}

``` 



les variables testées sont bien co-intégrées; nous pouvons lancer un modèle ARDL. 

```{r}
library(ARDL)
new_dataframe_train <- new_dataframe[new_dataframe$Date < "2023-01-01", ]


models_new <- auto_ardl(Close ~  GDPV + MACD , data = new_dataframe_train, max_order = 10)

# The top 20 models according to the AIC
models_new$top_orders

```


```{r}

# Charger les bibliothèques nécessaires
library(dplyr)
if (!require("vars")) install.packages("vars")

library(vars)

```



#modèle ARDL sur les log returns 

```{r}
# Charger les packages nécessaires
if (!require(tseries)) install.packages("tseries")
library(tseries)

# Supprimer les colonnes non numériques de final_database
df_numeric <- final_database[, sapply(final_database, is.numeric)]

# Initialiser un tableau pour stocker les résultats
stationarity_results_kpss <- data.frame(
  Variable = colnames(df_numeric),
  p_value_Level = NA,  # p-valeur pour la stationnarité en niveau
  p_value_Diff = NA,   # p-valeur pour la stationnarité après différenciation
  Stationarity = NA    # Classification finale : Stationnaire ou Non-stationnaire
)

# Boucle pour tester chaque variable
for (i in 1:ncol(df_numeric)) {
  var_name <- colnames(df_numeric)[i]
  variable <- df_numeric[[var_name]]
  
  # Test KPSS sur la série en niveau
  kpss_level <- kpss.test(na.omit(variable), null = "Level")
  p_value_level <- kpss_level$p.value
  
  # Test KPSS sur la série différenciée
  diff_variable <- diff(variable, differences = 1)
  kpss_diff <- kpss.test(na.omit(diff_variable), null = "Level")
  p_value_diff <- kpss_diff$p.value
  
  # Déterminer le statut de stationnarité
  if (p_value_level > 0.05) {
    status <- "I(0)"
  } else if (p_value_diff > 0.05) {
    status <- "I(1)"
  } else {
    status <- "I(2)"
  }
  
  # Ajouter les résultats au tableau
  stationarity_results_kpss[i, ] <- c(var_name, p_value_level, p_value_diff, status)
}

# Afficher les résultats
print(stationarity_results_kpss)


```

```{r}

i0_i1_vars <- stationarity_results_kpss$Variable[
  stationarity_results_kpss$Stationarity %in% c("I(0)", "I(1)")
]

# Vérifier les noms pour s'assurer qu'ils correspondent
i0_i1_vars <- intersect(colnames(final_database), i0_i1_vars)

# Filtrer les colonnes correspondantes dans le DataFrame original
filtered_df <- final_database[, c("Date", i0_i1_vars), drop = FALSE]
```

```{r}
cor_with_target <- cor(
  filtered_df$Return, 
  filtered_df[, !(names(filtered_df) %in% c("Return", "Date"))], 
  use = "complete.obs"
)

cor_with_target
```

```{r}
# Charger la bibliothèque nécessaire
library(lmtest)

# Liste des variables explicatives (exclure "Date" et "Return")
variables <- colnames(filtered_df)[!(colnames(filtered_df) %in% c("Date", "Return"))]

# Stocker les résultats bilatéraux
bilateral_results <- list()

# Tester la causalité de Granger dans les deux directions
for (var in variables) {
  cat("\n--- Test de Granger entre Return et", var, "---\n")
  
  # 1. Est-ce que la variable explicative Granger-cause la cible ?
  test1 <- grangertest(filtered_df$Return ~ filtered_df[[var]], order = 1)
  
  # 2. Est-ce que la cible Granger-cause la variable explicative ?
  test2 <- grangertest(filtered_df[[var]] ~ filtered_df$Return, order = 1)
  
  # Stocker les résultats
  bilateral_results[[var]] <- list(
    "Variable -> Cible" = test1,
    "Cible -> Variable" = test2
  )
  
  # Afficher les résultats
  cat("\n---", var, "Granger-cause Return ---\n")
  print(test1)
  cat("\n--- Return Granger-cause", var, "---\n")
  print(test2)
}
``` 


```{r}
new_dataframe <- final_database[, c("Date", "Return", "CPIH_YTYPCT")]

cor_matrix <- cor(new_dataframe[, -which(names(filtered_df) == "Date")], use = "complete.obs")

corrplot(cor_matrix, 
         method = "color",    # Affichage sous forme de couleur
         col = colorRampPalette(c("red", "white", "blue"))(200), # Palette de couleurs (rouge à bleu)
         type = "full",       # Afficher toute la matrice
         diag = FALSE,        # Ne pas afficher la diagonale
         addCoef.col = "black",  # Ajouter les coefficients de corrélation en noir
         number.cex = 0.7,    # Taille du texte des coefficients
         tl.cex = 0.8,        # Taille du texte des noms des variables
         tl.col = "black",    # Couleur du texte des noms des variables
         mar = c(0, 0, 1, 0)  # Ajustement des marges
)
new_dataframe$Williams_R <- NULL
```

```{r}
library(ARDL)
new_dataframe_train <- new_dataframe[new_dataframe$Date < "2023-01-01", ]


models_new <- auto_ardl(Return ~  CPIH_YTYPCT , data = new_dataframe_train, max_order = 10)

# The top 20 models according to the AIC
models_new$top_orders

```


```{r}
ardl_new <- models_new$best_model
ardl_new$order
summary(ardl_new)
# 1. Récupérer les résidus du modèle
residuals_ardl_new <- residuals(ardl_new)

# 2. Vérifier les résidus visuellement avec un graphique
par(mfrow = c(2, 2))  # Placer plusieurs graphiques sur la même fenêtre
plot(residuals_ardl_new, type = "l", main = "Graphique des Résidus", ylab = "Résidus", xlab = "Observations")
abline(h = 0, col = "red")  # Ajouter une ligne horizontale à 0

# Histogramme des résidus
hist(residuals_ardl_new, main = "Histogramme des Résidus", xlab = "Résidus", col = "blue", border = "black", breaks = 50)

# 4. Test d'autocorrélation des résidus (Durbin-Watson)
library(lmtest)
dwtest(ardl_new)

# 5. Afficher l'ACF (Autocorrélation des Résidus)
acf(residuals_ardl_new, main = "Autocorrélation des Résidus")

```

```{r}
bounds_f_test(ardl_new, case = 2)
bounds_f_test(ardl_new, case = 3)
```
Les variables sont cointégrées; on peut donc lancer un ECM 

Unrestricted Error Correction Model 
```{r}
uecm_new <- uecm(ardl_new)
summary(uecm_new)
```

```{r}
recm_new <- recm(uecm_new, case = 2)
summary(recm_new)
```


Here we have the short-run and the long-run multipliers (with standard errors, t-statistics and p-values).

```{r}
multipliers(ardl_new, type = "sr")
multipliers(ardl_new)
mult15 <- multipliers(ardl_new, type = 15, se = TRUE)
plot_delay(mult15, interval = 0.95)

```


```{r}
ardl_new_lm <- to_lm(ardl_new)

# Forecast using the in-sample data
insample_data <- ardl_new$model
predicted_values <- predict(ardl_new_lm, newdata = insample_data)

used_rows <- rownames(insample_data)

# Créer une nouvelle colonne pour les prédictions (initialisée à NA)
new_dataframe_train$Predicted <- NA

# Insérer les prédictions aux lignes correspondantes
new_dataframe_train$Predicted[as.numeric(used_rows)] <- predicted_values


```

```{r}
# Ajouter une colonne pour grouper par tranches de 5 ans
library(dplyr)
library(ggplot2)

# Ajouter les périodes de 5 ans
plot_data_train <- new_dataframe_train %>%
  mutate(
    Year = as.numeric(format(Date, "%Y")),  # Extraire l'année
    Period = paste0(floor(Year / 5) * 5, "-", floor(Year / 5) * 5 + 4)  # Grouper par tranches de 5 ans
  )

# Identifier toutes les tranches de 5 ans
periods <- unique(plot_data_train$Period)

# Générer un graphique pour chaque tranche de 5 ans
for (period in periods) {
  # Filtrer les données pour la tranche actuelle
  period_data <- filter(plot_data_train, Period == period)
  
  # Créer le graphique
  p <- ggplot(period_data, aes(x = Date)) +
    geom_line(aes(y = Return), color = 'black', linewidth = 1) +     # Série observée en noir
    geom_line(aes(y = Predicted), color = 'blue', linewidth = 1) +  # Prédictions en bleu
    labs(
      title = paste("Comparaison des prédictions ARDL - Période :", period),
      x = "Date", 
      y = "Retour"
    ) +
    theme_minimal() +
    theme(legend.position = "none")
  
  # Afficher le graphique
  print(p)
}

# Charger les bibliothèques nécessaires
library(dplyr)

# Calcul des erreurs globales (ensemble train)
errors_train <- plot_data_train$Return - plot_data_train$Predicted
rmse_train <- sqrt(mean(errors_train^2, na.rm = TRUE))  # RMSE
mae_train <- mean(abs(errors_train), na.rm = TRUE)      # MAE

cat("Performance globale sur l'ensemble train:\n")
cat("RMSE: ", rmse_train, "\n")
cat("MAE: ", mae_train, "\n")

# Sous-échantillon : octobre 2008
subsample_month_train <- plot_data_train %>%
  filter(Year == 2008 & format(Date, "%m") == "10")

# Calcul des erreurs pour octobre 2008
errors_month_train <- subsample_month_train$Return - subsample_month_train$Predicted
rmse_month_train <- sqrt(mean(errors_month_train^2, na.rm = TRUE))  # RMSE pour octobre 2008
mae_month_train <- mean(abs(errors_month_train), na.rm = TRUE)      # MAE pour octobre 2008

cat("Performance pour octobre 2008:\n")
cat("RMSE: ", rmse_month_train, "\n")
cat("MAE: ", mae_month_train, "\n")

```

```{r}
# Préparer le dataframe pour l'ensemble de test
new_dataframe_test <- new_dataframe[new_dataframe$Date >= "2023-01-01", ]

# Ajouter les décalages nécessaires pour Return et CPIH_YTYPCT
new_dataframe_test <- new_dataframe_test %>%
  mutate(
    L1_Return = lag(Return, 1, default = tail(new_dataframe_train$Return, 1)),
    L2_Return = lag(Return, 2, default = tail(new_dataframe_train$Return, 2)[1]),
    L3_Return = lag(Return, 3, default = tail(new_dataframe_train$Return, 3)[1]),
    L1_CPIH_YTYPCT = lag(CPIH_YTYPCT, 1, default = tail(new_dataframe_train$CPIH_YTYPCT, 1)),
    L2_CPIH_YTYPCT = lag(CPIH_YTYPCT, 2, default = tail(new_dataframe_train$CPIH_YTYPCT, 2)[1]),
    L3_CPIH_YTYPCT = lag(CPIH_YTYPCT, 3, default = tail(new_dataframe_train$CPIH_YTYPCT, 3)[1])
  )

# Renommer les colonnes pour correspondre à la syntaxe du modèle ARDL
new_dataframe_test <- new_dataframe_test %>%
  rename(
    `L(Return, 1)` = L1_Return,
    `L(Return, 2)` = L2_Return,
    `L(Return, 3)` = L3_Return,
    `L(CPIH_YTYPCT, 1)` = L1_CPIH_YTYPCT,
    `L(CPIH_YTYPCT, 2)` = L2_CPIH_YTYPCT,
    `L(CPIH_YTYPCT, 3)` = L3_CPIH_YTYPCT
  )

# Effectuer les prédictions avec le modèle ARDL converti en modèle linéaire
predictions_test <- predict(ardl_new_lm, newdata = new_dataframe_test)

# Ajouter les prédictions dans le dataframe de test
new_dataframe_test$Predicted <- predictions_test

# Calcul des erreurs
errors_test <- new_dataframe_test$Return - new_dataframe_test$Predicted

# Calcul des métriques de performance
rmse_test <- sqrt(mean(errors_test^2, na.rm = TRUE))
mae_test <- mean(abs(errors_test), na.rm = TRUE)

cat("Performance sur l'ensemble de test:\n")
cat("RMSE: ", rmse_test, "\n")
cat("MAE: ", mae_test, "\n")

# Graphique des prédictions vs valeurs observées
library(ggplot2)
ggplot(new_dataframe_test, aes(x = Date)) +
  geom_line(aes(y = Return), color = 'black', linewidth = 1, linetype = "solid") +  # Observé
  geom_line(aes(y = Predicted), color = 'blue', linewidth = 1, linetype = "dashed") +  # Prédictions
  labs(
    title = "Prédictions ARDL sur l'ensemble de test",
    x = "Date",
    y = "Return"
  ) +
  theme_minimal()

```


```{r}
# Dernier prix de clôture connu (celui de la fin de l'ensemble train)
last_train_price <- 6473.76

# Calcul des prix observés et prédits
new_dataframe_test <- new_dataframe_test %>%
  mutate(
    Observed_Price = last_train_price * cumprod(exp(Return)),  # Prix observés
    Predicted_Price = last_train_price * cumprod(exp(Predicted))  # Prix prédits
  )

# Vérifiez les premières lignes pour vous assurer de la cohérence
head(new_dataframe_test[, c("Date", "Observed_Price", "Predicted_Price")])

# Graphique des prix
ggplot(new_dataframe_test, aes(x = Date)) +
  geom_line(aes(y = Observed_Price), color = 'black', linewidth = 1, linetype = "solid") +  # Prix observés
  geom_line(aes(y = Predicted_Price), color = 'blue', linewidth = 1, linetype = "dashed") +  # Prix prédits
  labs(
    title = "Prix de clôture observés vs prédits",
    x = "Date",
    y = "Prix de clôture"
  ) +
  theme_minimal()

# Calcul des erreurs entre les prix observés et prédits
errors_prices <- new_dataframe_test$Observed_Price - new_dataframe_test$Predicted_Price

# Calcul du RMSE et du MAE sur les prix
rmse_prices <- sqrt(mean(errors_prices^2, na.rm = TRUE))  # RMSE
mae_prices <- mean(abs(errors_prices), na.rm = TRUE)      # MAE

# Affichage des résultats
cat("Performance sur les prix de clôture :\n")
cat("RMSE (Prix): ", rmse_prices, "\n")
cat("MAE (Prix): ", mae_prices, "\n")



```
