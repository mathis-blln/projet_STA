---
title: "creation_eco_var"
author: "BOUILLON Mathis"
date: "2025-01-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```



```{r, include = FALSE}

# Check and install necessary packages
if (!require("readr")) install.packages("readr")
if (!require("ggplot2")) install.packages("ggplot2")
if (!require("zoo")) install.packages("zoo")
if (!require("dplyr")) install.packages("dplyr")
if (!require("tidyr")) install.packages("tidyr")
if (!require("quantmod")) install.packages("quantmod")


# Load libraries
library(readr)
library(ggplot2)  # For creating plots
library(zoo)  # For managing quarterly time periods
library(dplyr)  # For data manipulation
library(tidyr)  # For data tidying
library(quantmod)
```



# Building the database

### Load data for France

```{r}
eco_data <- read_csv("../input/OECD.ECO.MAD,DSD_EO@DF_EO,1.2+FRA.UNR+CPIH_YTYPCT+IRL+IRS+YPH+GDP+GDPV+IRCB.Q.csv",show_col_types = FALSE)

# Display column names to understand the dataset structure
colnames(eco_data)

# Convert the TIME_PERIOD column to quarterly date format
eco_data$TIME_PERIOD <- as.yearqtr(eco_data$TIME_PERIOD, format="%Y-Q%q")

# Reshape the data to wide format for easier analysis
eco_data_wide <- eco_data %>%
  dplyr::select(TIME_PERIOD, MEASURE, OBS_VALUE) %>%
  tidyr::pivot_wider(
    names_from = MEASURE,   # Variables (e.g., GDP, GNP) will become columns
    values_from = OBS_VALUE # Associated values
  ) %>%
  arrange(TIME_PERIOD)

# Extract a list of variables (excluding TIME_PERIOD)
variables <- colnames(eco_data_wide)[-1]

# Create a scatter plot for each variable over time
for (var in variables) {
  print(
    ggplot(eco_data_wide, aes_string(x = "TIME_PERIOD", y = var)) +
      geom_point(color = "blue") +
      labs(title = paste("Scatter plot for", var),
           x = "Time (Quarters)",
           y = var) +
      theme_minimal()
  )
}
```

### Load data for the US

```{r}
eco_data_us <- read_csv("../input/OECD.ECO.MAD,DSD_EO@DF_EO,1.2+USA.CPI+UNR+IRCB.Q.csv",
                     show_col_types = FALSE)

# Convert the TIME_PERIOD column to quarterly date format
eco_data_us$TIME_PERIOD <- as.yearqtr(eco_data_us$TIME_PERIOD, format="%Y-Q%q")

# Reshape the US data to wide format
eco_data_wide_us <- eco_data_us %>%
  dplyr::select(TIME_PERIOD, MEASURE, OBS_VALUE) %>%
  tidyr::pivot_wider(
    names_from = MEASURE,   # Variables (e.g., GDP, GNP) will become columns
    values_from = OBS_VALUE # Associated values
  ) %>%
  dplyr::arrange(TIME_PERIOD)

# Rename columns for the US dataset to distinguish them
colnames(eco_data_wide_us) <- ifelse(colnames(eco_data_wide_us) != "TIME_PERIOD", 
                                     paste0(colnames(eco_data_wide_us), "_us"), 
                                     colnames(eco_data_wide_us))
```

### Combine French and US data
```{r}
# Merge the two datasets on TIME_PERIOD (left join to retain all rows from the French dataset)
eco_data_combined <- merge(eco_data_wide, eco_data_wide_us, by = "TIME_PERIOD", all.x = TRUE)


```


### Interpolate data to create daily observations

```{r}

# Ensure TIME_PERIOD is in quarterly date format
eco_data_combined$TIME_PERIOD <- as.yearqtr(eco_data_combined$TIME_PERIOD, format="%Y-Q%q")

# Convert quarters to actual dates, e.g., the first day of each quarter
eco_data_combined$DATE <- as.Date(eco_data_combined$TIME_PERIOD)

# Create a daily sequence of dates between the first and last available dates
date_seq <- seq(from = min(eco_data_combined$DATE), to = max(eco_data_combined$DATE), by = "day")

# Define an interpolation function for each column
interpolate_column <- function(column_values, date_seq, eco_data) {
  approx_dates <- as.numeric(eco_data$DATE)  # Convert dates to numeric for interpolation
  approx_values <- column_values
  approx_result <- approx(approx_dates, approx_values, xout = as.numeric(date_seq), method = "linear")$y
  return(approx_result)
}

# Create an empty dataframe for daily observations
eco_data_daily <- data.frame(DATE = date_seq)

# Apply interpolation to all columns except TIME_PERIOD and DATE
for (col in colnames(eco_data_combined)[-c(1, ncol(eco_data_combined))]) {
  eco_data_daily[[col]] <- interpolate_column(eco_data_combined[[col]], date_seq, eco_data_combined)
}

# Display the first few rows of the interpolated daily data
head(eco_data_daily)

```

### Extract data for predictions 

```{r}
# Filter data for dates after 2024-10-30
eco_data_after_date <- eco_data_daily %>% 
  filter(DATE > as.Date("2024-10-30"))

# Save the filtered dataset to a CSV file
write.csv(eco_data_after_date, "../input/eco_data_after_2024-10-30.csv", row.names = FALSE)

```

We perform a join to integrate the CAC 40 data into the dataset and remove observations with missing CAC 40 values, which typically occur on weekends or non-trading days.

```{r}
# Create a dataframe for CAC 40 values with corresponding dates
# Download CAC40 index 
cac40 <- getSymbols("^FCHI", src = "yahoo", from = "2000-01-03", to = "2024-10-29", auto.assign = FALSE)

cac40_close <- na.omit(Cl(cac40)) 
cac40_close_df <- data.frame(Date = index(cac40_close), Value = coredata(cac40_close))
colnames(cac40_close_df) <- c("DATE", "CAC40")

# Join CAC 40 values to the daily data based on the DATE column
eco_data_daily <- left_join(eco_data_daily, cac40_close_df, by = "DATE")

# Remove rows with missing CAC 40 values (e.g., weekends)
eco_data_daily_clean <- eco_data_daily[!is.na(eco_data_daily$CAC40), ]

# Save the cleaned dataset to a CSV file
write.csv(eco_data_daily_clean, "../input/eco_data_daily_clean.csv", row.names = FALSE)

```